{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9NbC6gOemq_"
   },
   "source": [
    "## 과제 설명\n",
    "법률 문서에 대한 원문을 가장 잘 나타내는 3개의 문장을 추출하는 문서 요약 모델 개발\n",
    "    \n",
    "### 데이터 설명\n",
    "- 개요 : 뉴스 기사, 기고문, 잡지, 법률 (판결문) 등 다양한 영역에서 추출된 텍스트 데이터와 요약본 40만 건\n",
    "- 입출력: \n",
    "    - 입력: 문장별로 나뉜 법률 문서 원문, 예) 법률 문서 = [문장1, 문장2, ..., 문장K], K : 문서 길이\n",
    "    - 출력: 요약문에 포함될 문장 인덱스 3개\n",
    "- 데이터셋 구성\n",
    "    - 학습 데이터:\n",
    "        - train.json : 24,027개의 법률 문서 아이디 (id), 원문 (article_original), 요약문 (extractive)\n",
    "    - 테스트 데이터:\n",
    "        - test.json : 3,004개의 법률 문서 아이디 (id), 원문 (article_original)\n",
    "\n",
    "### 사용 pretrained 모델\n",
    " `beomi/KcELECTRA-base` \n",
    "[Documentation](https://github.com/Beomi/KcELECTRA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raqeQ-fCemrD"
   },
   "source": [
    "## 세팅\n",
    "### 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cLGAzh4ZemrE"
   },
   "outputs": [],
   "source": [
    "# 설치되지 않은 라이브러리의 경우, 주석 해제 후 코드를 실행하여 설치\n",
    "# !pip install pytorch-pretrained-bert\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cp9LsiuSfHmU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.mkdir(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QejfU_Z7emrF"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 및 코드 파일 불러오기\n",
    "# !pip install torch\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CIaWjefYemrG"
   },
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 경로 설정\n",
    "ROOT_PATH = './'\n",
    "DATA_DIR = './data'\n",
    "MODEL_DIR = DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-MQRlsCemrH"
   },
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "C_NfPl1UemrI"
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "EVAL_BATCH_SIZE = 32\n",
    "\n",
    "# 학습 데이터만 있으니 학습 데이터셋 비율과 validation 데이터셋 비율을 나눔\n",
    "TRAIN_RATIO = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVNzfovOemrJ"
   },
   "source": [
    "- `__init__` 에서 tokenizer는 transformers 라이브러리에서 AutoTokenizer를 사용합니다. 이 외에도 원하는 토크나이저를 적용해 다양한 실험을 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E3-2BwM7emrJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "# from pytorch_pretrained_bert import BertTokenizer\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\") \n",
    "        self.inputs, self.labels = self.data_loader()\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        \n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode + '_X.pt')):\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            labels = torch.load(os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        else:\n",
    "            file_path = os.path.join(self.data_dir, 'train.json')\n",
    "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
    "          \n",
    "            if self.mode == 'train':\n",
    "                df = df.loc[:TRAIN_RATIO*int(len(df)), :]\n",
    "            elif self.mode == 'val':\n",
    "                df = df.loc[TRAIN_RATIO*int(len(df)):, :]\n",
    "\n",
    "            inputs = pd.DataFrame(columns=['src'])\n",
    "            labels = pd.DataFrame(columns=['trg'])\n",
    "            inputs['src'] =  df['article_original']\n",
    "            labels['trg'] =  df['extractive']\n",
    "          \n",
    "            # Preprocessing\n",
    "            inputs, labels = self.preprocessing(inputs, labels)\n",
    "            # Save data\n",
    "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            torch.save(labels, os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        inputs = inputs.values\n",
    "        labels = labels.values\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def pad(self, data, pad_id, max_len):\n",
    "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
    "        return padded_data\n",
    "\n",
    "    def preprocessing(self, inputs, labels):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        #Encoding original text\n",
    "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
    "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
    "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
    "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
    "\n",
    "        ##Padding\n",
    "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
    "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
    "        inputs['segs'] = self.pad(inputs.segs, 0, max_encoding_len)\n",
    "        inputs['clss'] = self.pad(inputs.clss, -1, max_label_len)\n",
    "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
    "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
    "\n",
    "        #Binarize label {Extracted sentence : 1, Not Extracted sentence : 0}\n",
    "        labels = labels['trg'].map(lambda  x: torch.tensor([1 if i in x else 0 for i in range(max_label_len)]))\n",
    "        return inputs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return [self.inputs[index][i] for i in range(5)], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i56s2300emrL",
    "outputId": "e6fb5ee6-e20b-4813-c7fd-3fa0ffe4de36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing train dataset..\n",
      "0        []\n",
      "1        []\n",
      "2        []\n",
      "3        []\n",
      "4        []\n",
      "         ..\n",
      "21620    []\n",
      "21621    []\n",
      "21622    []\n",
      "21623    []\n",
      "21624    []\n",
      "Name: trg, Length: 21625, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing val dataset..\n",
      "21625    []\n",
      "21626    []\n",
      "21627    []\n",
      "21628    []\n",
      "21629    []\n",
      "         ..\n",
      "24022    []\n",
      "24023    []\n",
      "24024    []\n",
      "24025    []\n",
      "24026    []\n",
      "Name: trg, Length: 2402, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train')\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shAoPvz4emrM"
   },
   "source": [
    "## 모델설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fUA2-7ZHemrN"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.0005\n",
    "WEIGHT_DECAY = 0.00001\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOPPING_PATIENCE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZORs3IWemrN"
   },
   "source": [
    "- 한국어 자연어 처리의 pretrained model인 KcELECTRA 깃헙 [https://github.com/Beomi/KcELECTRA] 참고\n",
    "- !주의! 모델이 무거우니 사용하는 파라미터 개수와 개발 환경 등을 고려하여 인코더 등을 선택하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WR_-OJ8OemrO"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import transformers\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class Summarizer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(Summarizer, self).__init__()\n",
    "        self.encoder = transformers.GPT2Model.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x, segs, clss, mask, mask_clss, sentence_range=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        top_vec = self.encoder(input_ids = x.long(), attention_mask = mask.float()).last_hidden_state\n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss.long()]\n",
    "        sents_vec = sents_vec * mask_clss[:, :, None].float()\n",
    "        h = self.fc(sents_vec).squeeze(-1)\n",
    "        sent_scores = self.sigmoid(h) * mask_clss.float()\n",
    "        return sent_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3Av7q4remrO",
    "outputId": "46adc045-2585-4945-805d-8d95a0b50069"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = Summarizer().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8nnoSTkCemrO"
   },
   "outputs": [],
   "source": [
    "def Hitrate(y_true, y_pred):\n",
    "    \"\"\" Metric 함수 반환하는 함수\n",
    "\n",
    "    Returns:\n",
    "        metric_fn (Callable)\n",
    "    \"\"\"\n",
    "    hitrate = np.array([len(list(set(ans).intersection(y_true[i])))/3 for i, ans in enumerate(y_pred)])\n",
    "    score = np.mean(hitrate)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-mUzYFAFemrP"
   },
   "outputs": [],
   "source": [
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "loss_fn = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "# Set metrics\n",
    "metric_fn = Hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l_VWHIBHemrP"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int, verbose: bool, logger:logging.RootLogger=None)-> None:\n",
    "        \"\"\" 초기화\n",
    "\n",
    "        Args:\n",
    "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "            weight_path (str): weight 저장경로\n",
    "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.logger = logger\n",
    "        self.stop = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\n",
    "\n",
    "        Args:\n",
    "            loss (float):\n",
    "\n",
    "        Examples:\n",
    "            \n",
    "        Note:\n",
    "            \n",
    "        \"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopper, Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "\n",
    "            if self.verbose:\n",
    "                self.logger.info(msg) if self.logger else print(msg)\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.save_model = True\n",
    "            msg = f\"Early stopper, Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)\n",
    "\n",
    "            if self.verbose:\n",
    "                self.logger.info(msg) if self.logger else print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ONw9u03nemrP"
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" Trainer\n",
    "        epoch에 대한 학습 및 검증 절차 정의\n",
    "    \n",
    "    Attributes:\n",
    "        model (`model`)\n",
    "        device (str)\n",
    "        loss_fn (Callable)\n",
    "        metric_fn (Callable)\n",
    "        optimizer (`optimizer`)\n",
    "        scheduler (`scheduler`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, loss_fn, metric_fn, optimizer=None, scheduler=None, logger=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metric_fn = metric_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.logger = logger\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\n",
    "\n",
    "        Args:\n",
    "            dataloader (`dataloader`)\n",
    "            epoch_index (int)\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.train_total_loss = 0\n",
    "        pred_lst = []\n",
    "        target_lst = []\n",
    "        for batch_index, (data, target) in enumerate(tqdm(dataloader)):\n",
    "            self.optimizer.zero_grad()\n",
    "            src = data[0].to(self.device)\n",
    "            clss = data[1].to(self.device)\n",
    "            segs = data[2].to(self.device)\n",
    "            mask = data[3].to(self.device)\n",
    "            mask_clss = data[4].to(self.device)\n",
    "            target = target.float().to(self.device)\n",
    "            sent_score = self.model(src, segs, clss, mask, mask_clss)\n",
    "            loss = self.loss_fn(sent_score, target)\n",
    "            loss = (loss * mask_clss.float()).sum()\n",
    "            self.train_total_loss += loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "            try:\n",
    "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
    "            except:\n",
    "                print(target)\n",
    "                sys.exit()\n",
    "                \n",
    "        self.train_mean_loss = self.train_total_loss / len(dataloader)\n",
    "        self.train_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train, loss: {self.train_mean_loss}, Score: {self.train_score}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "\n",
    "        Args:\n",
    "            dataloader (`dataloader`)\n",
    "            epoch_index (int)\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.val_total_loss = 0\n",
    "        pred_lst = []\n",
    "        target_lst = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (data, target) in enumerate(tqdm(dataloader)):\n",
    "                src = data[0].to(self.device)\n",
    "                clss = data[1].to(self.device)\n",
    "                segs = data[2].to(self.device)\n",
    "                mask = data[3].to(self.device)\n",
    "                mask_clss = data[4].to(self.device)\n",
    "                target = target.float().to(self.device)\n",
    "                sent_score = self.model(src, segs, clss, mask, mask_clss)\n",
    "                loss = self.loss_fn(sent_score, target)\n",
    "                loss = (loss * mask_clss.float()).sum()\n",
    "                self.val_total_loss += loss\n",
    "                pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
    "            self.val_mean_loss = self.val_total_loss / len(dataloader)\n",
    "            self.validation_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
    "            msg = f'Epoch {epoch_index}, Validation, loss: {self.val_mean_loss}, Score: {self.validation_score}'\n",
    "            print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "77HYQX6FemrQ"
   },
   "outputs": [],
   "source": [
    "# Set trainer\n",
    "trainer = Trainer(model, DEVICE, loss_fn, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t06v-mOPemrQ"
   },
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L54C4-6gemrQ",
    "outputId": "96980e6f-adc5-4181-c267-cfc0276b4e91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2704 [00:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 7.81 GiB total capacity; 6.31 GiB already allocated; 35.00 MiB free; 6.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bfb8116803fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-b0f2d23cbdf1>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, dataloader, epoch_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmask_clss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0msent_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_clss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_clss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d053015b9b4b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, segs, clss, mask, mask_clss, sentence_range)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \"\"\"\n\u001b[1;32m     18\u001b[0m         \"\"\"\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtop_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0msents_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msents_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msents_vec\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_clss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    885\u001b[0m                 )\n\u001b[1;32m    886\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    888\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 7.81 GiB total capacity; 6.31 GiB already allocated; 35.00 MiB free; 6.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "criterion = 0\n",
    "\n",
    "for epoch_index in range(EPOCHS):\n",
    "    \n",
    "    trainer.train_epoch(train_dataloader, epoch_index=epoch_index)\n",
    "    trainer.validate_epoch(validation_dataloader, epoch_index=epoch_index)\n",
    "   \n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if trainer.validation_score > criterion:\n",
    "        criterion = trainer.validation_score\n",
    "        check_point = {\n",
    "            'model' : model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        \n",
    "        torch.save(check_point, os.path.join(MODEL_DIR, 'best.pt'))\n",
    "        \n",
    "        \n",
    "print(\"train finished, best.pt saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4TETXcIemrR"
   },
   "source": [
    "## 추론\n",
    "테스트 데이터의 타겟 변수를 `sample_submission.csv` 양식에 맞춰 저장하고, 해당 제출파일을 Inclass에 제출하시면 점수를 확인할 수 있습니다.\n",
    "\n",
    "여러분의 모델의 추론 결과로 나온 문서 당 세 개의 요약 인덱스에 해당하는 \"idx_#\"을 1로 채워 제출 파일을 만듭니다(현재는 아래 보시는 바와 같이 모두 0으로 채워져 있습니다). ID 값을 기준으로 채점을 진행하는 점 유의해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dlvE85eSemrR",
    "outputId": "c6c0ffa8-a9eb-4cfc-ea7c-e8d213b75295"
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(os.path.join(DATA_DIR,'sample_submission.csv'))\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tir-zxUIemrR"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 클래스 정의\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\" CustomDataset과 비슷한 구조이지만 레이블이 주어지지 않음을 염두 \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\") \n",
    "        self.inputs = self.data_loader()\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode+'_X.pt')):\n",
    "            # torch tensor 불러오기\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "        else:\n",
    "            # json 파일 불러오기\n",
    "            file_path = os.path.join(self.data_dir, self.mode + '.json')\n",
    "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
    "            inputs = pd.DataFrame(columns=['src'])\n",
    "            inputs['src'] =  df['article_original']\n",
    "      \n",
    "            # 전처리\n",
    "            inputs = self.preprocessing(inputs)\n",
    "            \n",
    "            # 다음부터는 전처리 과정을 반복하지 않기 위해 tensor 저장\n",
    "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "\n",
    "        inputs = inputs.values\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def pad(self, data, pad_id, max_len):\n",
    "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
    "        return padded_data\n",
    "\n",
    "    def preprocessing(self, inputs):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        \n",
    "        #Encoding original text\n",
    "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
    "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
    "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
    "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
    "\n",
    "        ##Padding\n",
    "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
    "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
    "        inputs['segs'] = self.pad(inputs.segs, 0, max_encoding_len)\n",
    "        inputs['clss'] = self.pad(inputs.clss, -1, max_label_len)\n",
    "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
    "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
    "     \n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return [self.inputs[index][i] for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIG2Pui_emrS",
    "outputId": "6a57b5a7-4cc5-4f74-dbae-b4023fccd75e"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 로드\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, mode = 'test')\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtESxi9YemrS",
    "outputId": "7bba9d9b-2195-4eb8-b893-e135a1b6bb83"
   },
   "outputs": [],
   "source": [
    "\"\"\" 이전에 학습한 모델 weight파일을 불러 추론하려면 아래 주석을 풀고 실행\n",
    "    학습 진행 후 바로 추론하는 경우 학습 과정의 model 사용 (주석 풀지 않고 실행) \"\"\"\n",
    "MODEL_DIR = os.path.join(MODEL_DIR, 'best.pt')\n",
    "model = Summarizer().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_DIR)['model'])\n",
    "\n",
    "# 추론\n",
    "model.eval()\n",
    "\n",
    "# 추론 결과를 pred 리스트로 저장할 예정\n",
    "pred_lst = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (data) in enumerate(test_dataloader):\n",
    "        src = data[0].to(DEVICE)\n",
    "        clss = data[1].to(DEVICE)\n",
    "        segs = data[2].to(DEVICE)\n",
    "        mask = data[3].to(DEVICE)\n",
    "        mask_clss = data[4].to(DEVICE)\n",
    "        sent_score = model(src, segs, clss, mask, mask_clss)\n",
    "        pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "            \n",
    "        # 진행과정 출력\n",
    "        if batch_index % 150 == 0:\n",
    "            print(f'Prediction: {batch_index}/{len(test_dataloader)} completed')\n",
    "    print(\"Prediction all completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5R0oUTRemrS",
    "outputId": "3151e147-c8a1-491f-e90c-ee0a623834e2"
   },
   "outputs": [],
   "source": [
    "pred_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "GFUS1riiemrS",
    "outputId": "35a97ae3-4f3b-4a45-9e25-73f1bb1e4918"
   },
   "outputs": [],
   "source": [
    "# 제출 파일\n",
    "for i,txt in enumerate(pred_lst):\n",
    "    submit.iloc[i, 1] += txt[0]+1\n",
    "    submit.iloc[i, 2] += txt[1]+1\n",
    "    submit.iloc[i, 3] += txt[2]+1\n",
    "    # print(submit.iloc[i, 1])\n",
    "submit[submit[\"ID\"] == 83319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WM4WBBuRemrS"
   },
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(ROOT_PATH, 'prediction.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFvILhRcemrS"
   },
   "outputs": [],
   "source": [
    "predc = pd.read_csv(\"./prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "57uOhrTN7Nra",
    "outputId": "1a647093-8e10-4bf3-dccf-df46f929163a"
   },
   "outputs": [],
   "source": [
    "predc[predc[\"ID\"] == 83319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_4MPMIX7OeO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "korean_nlp_legal_docs_torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow 2.7 on Python 3.8 & CUDA 11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
