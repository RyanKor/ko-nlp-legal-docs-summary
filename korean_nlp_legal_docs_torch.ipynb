{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9NbC6gOemq_"
      },
      "source": [
        "## 과제 설명\n",
        "법률 문서에 대한 원문을 가장 잘 나타내는 3개의 문장을 추출하는 문서 요약 모델 개발\n",
        "    \n",
        "### 데이터 설명\n",
        "- 개요 : 뉴스 기사, 기고문, 잡지, 법률 (판결문) 등 다양한 영역에서 추출된 텍스트 데이터와 요약본 40만 건\n",
        "- 입출력: \n",
        "    - 입력: 문장별로 나뉜 법률 문서 원문, 예) 법률 문서 = [문장1, 문장2, ..., 문장K], K : 문서 길이\n",
        "    - 출력: 요약문에 포함될 문장 인덱스 3개\n",
        "- 데이터셋 구성\n",
        "    - 학습 데이터:\n",
        "        - train.json : 24,027개의 법률 문서 아이디 (id), 원문 (article_original), 요약문 (extractive)\n",
        "    - 테스트 데이터:\n",
        "        - test.json : 3,004개의 법률 문서 아이디 (id), 원문 (article_original)\n",
        "\n",
        "### 사용 pretrained 모델\n",
        " `beomi/KcELECTRA-base` \n",
        "[Documentation](https://github.com/Beomi/KcELECTRA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raqeQ-fCemrD"
      },
      "source": [
        "## 세팅\n",
        "### 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cLGAzh4ZemrE"
      },
      "outputs": [],
      "source": [
        "# 설치되지 않은 라이브러리의 경우, 주석 해제 후 코드를 실행하여 설치\n",
        "# !pip install pytorch-pretrained-bert\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cp9LsiuSfHmU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.mkdir(\"./data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QejfU_Z7emrF"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 및 코드 파일 불러오기\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CIaWjefYemrG"
      },
      "outputs": [],
      "source": [
        "# 시드 고정\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Set device\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 경로 설정\n",
        "ROOT_PATH = './'\n",
        "DATA_DIR = './data'\n",
        "MODEL_DIR = DATA_DIR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-MQRlsCemrH"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C_NfPl1UemrI"
      },
      "outputs": [],
      "source": [
        "# hyper-parameters\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "EVAL_BATCH_SIZE = 32\n",
        "\n",
        "# 학습 데이터만 있으니 학습 데이터셋 비율과 validation 데이터셋 비율을 나눔\n",
        "TRAIN_RATIO = 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVNzfovOemrJ"
      },
      "source": [
        "- `__init__` 에서 tokenizer는 transformers 라이브러리에서 AutoTokenizer를 사용합니다. 이 외에도 원하는 토크나이저를 적용해 다양한 실험을 진행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E3-2BwM7emrJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "from itertools import chain\n",
        "import json\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, mode):\n",
        "        self.data_dir = data_dir\n",
        "        self.mode = mode\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
        "        self.inputs, self.labels = self.data_loader()\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading ' + self.mode + ' dataset..')\n",
        "        \n",
        "        if os.path.isfile(os.path.join(self.data_dir, self.mode + '_X.pt')):\n",
        "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
        "            labels = torch.load(os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
        "\n",
        "        else:\n",
        "            file_path = os.path.join(self.data_dir, 'train.json')\n",
        "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
        "          \n",
        "            if self.mode == 'train':\n",
        "                df = df.loc[:TRAIN_RATIO*int(len(df)), :]\n",
        "            elif self.mode == 'val':\n",
        "                df = df.loc[TRAIN_RATIO*int(len(df)):, :]\n",
        "\n",
        "            inputs = pd.DataFrame(columns=['src'])\n",
        "            labels = pd.DataFrame(columns=['trg'])\n",
        "            inputs['src'] =  df['article_original']\n",
        "            labels['trg'] =  df['extractive']\n",
        "          \n",
        "            # Preprocessing\n",
        "            inputs, labels = self.preprocessing(inputs, labels)\n",
        "            # Save data\n",
        "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
        "            torch.save(labels, os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
        "\n",
        "        inputs = inputs.values\n",
        "        labels = labels.values\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def pad(self, data, pad_id, max_len):\n",
        "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
        "        return padded_data\n",
        "\n",
        "    def preprocessing(self, inputs, labels):\n",
        "        print('Preprocessing ' + self.mode + ' dataset..')\n",
        "        #Encoding original text\n",
        "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
        "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
        "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
        "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
        "\n",
        "        ##Padding\n",
        "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
        "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
        "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
        "        inputs['segs'] = self.pad(inputs.segs, 0, max_encoding_len)\n",
        "        inputs['clss'] = self.pad(inputs.clss, -1, max_label_len)\n",
        "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
        "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
        "\n",
        "        #Binarize label {Extracted sentence : 1, Not Extracted sentence : 0}\n",
        "        labels = labels['trg'].map(lambda  x: torch.tensor([1 if i in x else 0 for i in range(max_label_len)]))\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return [self.inputs[index][i] for i in range(5)], self.labels[index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i56s2300emrL",
        "outputId": "e6fb5ee6-e20b-4813-c7fd-3fa0ffe4de36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train dataset..\n",
            "Loading val dataset..\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train')\n",
        "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val')\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shAoPvz4emrM"
      },
      "source": [
        "## 모델설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fUA2-7ZHemrN"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 0.0005\n",
        "WEIGHT_DECAY = 0.00001\n",
        "NUM_WORKERS = 0\n",
        "EARLY_STOPPING_PATIENCE = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZORs3IWemrN"
      },
      "source": [
        "- 한국어 자연어 처리의 pretrained model인 KcELECTRA 깃헙 [https://github.com/Beomi/KcELECTRA] 참고\n",
        "- !주의! 모델이 무거우니 사용하는 파라미터 개수와 개발 환경 등을 고려하여 인코더 등을 선택하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WR_-OJ8OemrO"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import transformers\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "class Summarizer(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        super(Summarizer, self).__init__()\n",
        "        self.encoder = transformers.DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "        self.fc = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x, segs, clss, mask, mask_clss, sentence_range=None):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        top_vec = self.encoder(input_ids = x.long(), attention_mask = mask.float()).last_hidden_state\n",
        "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss.long()]\n",
        "        sents_vec = sents_vec * mask_clss[:, :, None].float()\n",
        "        h = self.fc(sents_vec).squeeze(-1)\n",
        "        sent_scores = self.sigmoid(h) * mask_clss.float()\n",
        "        return sent_scores\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Av7q4remrO",
        "outputId": "46adc045-2585-4945-805d-8d95a0b50069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = Summarizer().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8nnoSTkCemrO"
      },
      "outputs": [],
      "source": [
        "def Hitrate(y_true, y_pred):\n",
        "    \"\"\" Metric 함수 반환하는 함수\n",
        "\n",
        "    Returns:\n",
        "        metric_fn (Callable)\n",
        "    \"\"\"\n",
        "    hitrate = np.array([len(list(set(ans).intersection(y_true[i])))/3 for i, ans in enumerate(y_pred)])\n",
        "    score = np.mean(hitrate)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-mUzYFAFemrP"
      },
      "outputs": [],
      "source": [
        "# Set optimizer, scheduler, loss function, metric function\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
        "loss_fn = torch.nn.BCELoss(reduction='none')\n",
        "\n",
        "# Set metrics\n",
        "metric_fn = Hitrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "l_VWHIBHemrP"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "class LossEarlyStopper():\n",
        "    \"\"\"Early stopper\n",
        "    \n",
        "    Attributes:\n",
        "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
        "        verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
        "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
        "        min_loss (float): 최소 loss\n",
        "        stop (bool): True 일 때 학습 중단\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patience: int, verbose: bool, logger:logging.RootLogger=None)-> None:\n",
        "        \"\"\" 초기화\n",
        "\n",
        "        Args:\n",
        "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
        "            weight_path (str): weight 저장경로\n",
        "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.patience_counter = 0\n",
        "        self.min_loss = np.Inf\n",
        "        self.logger = logger\n",
        "        self.stop = False\n",
        "\n",
        "    def check_early_stopping(self, loss: float)-> None:\n",
        "        \"\"\"Early stopping 여부 판단\n",
        "\n",
        "        Args:\n",
        "            loss (float):\n",
        "\n",
        "        Examples:\n",
        "            \n",
        "        Note:\n",
        "            \n",
        "        \"\"\"  \n",
        "\n",
        "        if self.min_loss == np.Inf:\n",
        "            self.min_loss = loss\n",
        "            # self.save_checkpoint(loss=loss, model=model)\n",
        "\n",
        "        elif loss > self.min_loss:\n",
        "            self.patience_counter += 1\n",
        "            msg = f\"Early stopper, Early stopping counter {self.patience_counter}/{self.patience}\"\n",
        "\n",
        "            if self.patience_counter == self.patience:\n",
        "                self.stop = True\n",
        "\n",
        "            if self.verbose:\n",
        "                self.logger.info(msg) if self.logger else print(msg)\n",
        "                \n",
        "        elif loss <= self.min_loss:\n",
        "            self.save_model = True\n",
        "            msg = f\"Early stopper, Validation loss decreased {self.min_loss} -> {loss}\"\n",
        "            self.min_loss = loss\n",
        "            # self.save_checkpoint(loss=loss, model=model)\n",
        "\n",
        "            if self.verbose:\n",
        "                self.logger.info(msg) if self.logger else print(msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ONw9u03nemrP"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    \"\"\" Trainer\n",
        "        epoch에 대한 학습 및 검증 절차 정의\n",
        "    \n",
        "    Attributes:\n",
        "        model (`model`)\n",
        "        device (str)\n",
        "        loss_fn (Callable)\n",
        "        metric_fn (Callable)\n",
        "        optimizer (`optimizer`)\n",
        "        scheduler (`scheduler`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, device, loss_fn, metric_fn, optimizer=None, scheduler=None, logger=None):\n",
        "        \"\"\" 초기화\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.metric_fn = metric_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.logger = logger\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 학습 절차\n",
        "\n",
        "        Args:\n",
        "            dataloader (`dataloader`)\n",
        "            epoch_index (int)\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        self.train_total_loss = 0\n",
        "        pred_lst = []\n",
        "        target_lst = []\n",
        "        for batch_index, (data, target) in enumerate(tqdm(dataloader)):\n",
        "            self.optimizer.zero_grad()\n",
        "            src = data[0].to(self.device)\n",
        "            clss = data[1].to(self.device)\n",
        "            segs = data[2].to(self.device)\n",
        "            mask = data[3].to(self.device)\n",
        "            mask_clss = data[4].to(self.device)\n",
        "            target = target.float().to(self.device)\n",
        "            sent_score = self.model(src, segs, clss, mask, mask_clss)\n",
        "            loss = self.loss_fn(sent_score, target)\n",
        "            loss = (loss * mask_clss.float()).sum()\n",
        "            self.train_total_loss += loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "            pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
        "            try:\n",
        "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
        "            except:\n",
        "                print(target)\n",
        "                sys.exit()\n",
        "                \n",
        "        self.train_mean_loss = self.train_total_loss / len(dataloader)\n",
        "        self.train_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
        "        msg = f'Epoch {epoch_index}, Train, loss: {self.train_mean_loss}, Score: {self.train_score}'\n",
        "        print(msg)\n",
        "\n",
        "    def validate_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
        "\n",
        "        Args:\n",
        "            dataloader (`dataloader`)\n",
        "            epoch_index (int)\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        self.val_total_loss = 0\n",
        "        pred_lst = []\n",
        "        target_lst = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_index, (data, target) in enumerate(tqdm(dataloader)):\n",
        "                src = data[0].to(self.device)\n",
        "                clss = data[1].to(self.device)\n",
        "                segs = data[2].to(self.device)\n",
        "                mask = data[3].to(self.device)\n",
        "                mask_clss = data[4].to(self.device)\n",
        "                target = target.float().to(self.device)\n",
        "                sent_score = self.model(src, segs, clss, mask, mask_clss)\n",
        "                loss = self.loss_fn(sent_score, target)\n",
        "                loss = (loss * mask_clss.float()).sum()\n",
        "                self.val_total_loss += loss\n",
        "                pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
        "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
        "            self.val_mean_loss = self.val_total_loss / len(dataloader)\n",
        "            self.validation_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
        "            msg = f'Epoch {epoch_index}, Validation, loss: {self.val_mean_loss}, Score: {self.validation_score}'\n",
        "            print(msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "77HYQX6FemrQ"
      },
      "outputs": [],
      "source": [
        "# Set trainer\n",
        "trainer = Trainer(model, DEVICE, loss_fn, metric_fn, optimizer, scheduler)\n",
        "\n",
        "# Set earlystopper\n",
        "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t06v-mOPemrQ"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L54C4-6gemrQ",
        "outputId": "96980e6f-adc5-4181-c267-cfc0276b4e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2704/2704 [11:16<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train, loss: 37.38749694824219, Score: 0.5852639691714836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:21<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Validation, loss: 138.2972869873047, Score: 0.6236469608659451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2704/2704 [11:16<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train, loss: 34.275936126708984, Score: 0.6344662813102119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:21<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Validation, loss: 131.5118865966797, Score: 0.6411323896752706\n",
            "Early stopper, Validation loss decreased 138.2972869873047 -> 131.5118865966797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2704/2704 [11:16<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train, loss: 31.95185089111328, Score: 0.665325626204239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:21<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Validation, loss: 131.8885498046875, Score: 0.6514016097696363\n",
            "Early stopper, Early stopping counter 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2704/2704 [11:16<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train, loss: 27.50633430480957, Score: 0.7262273603082852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:21<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Validation, loss: 144.5745086669922, Score: 0.631834582292534\n",
            "Early stopper, Early stopping counter 2/2\n",
            "Early stopped\n",
            "train finished, best.pt saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# TRAIN\n",
        "from tqdm import tqdm\n",
        "\n",
        "start = time.time()\n",
        "criterion = 0\n",
        "\n",
        "for epoch_index in range(EPOCHS):\n",
        "    \n",
        "    trainer.train_epoch(train_dataloader, epoch_index=epoch_index)\n",
        "    trainer.validate_epoch(validation_dataloader, epoch_index=epoch_index)\n",
        "   \n",
        "    # early_stopping check\n",
        "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
        "\n",
        "    if early_stopper.stop:\n",
        "        print('Early stopped')\n",
        "        break\n",
        "\n",
        "    if trainer.validation_score > criterion:\n",
        "        criterion = trainer.validation_score\n",
        "        check_point = {\n",
        "            'model' : model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "        \n",
        "        torch.save(check_point, os.path.join(MODEL_DIR, 'best.pt'))\n",
        "        \n",
        "        \n",
        "print(\"train finished, best.pt saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4TETXcIemrR"
      },
      "source": [
        "## 추론\n",
        "테스트 데이터의 타겟 변수를 `sample_submission.csv` 양식에 맞춰 저장하고, 해당 제출파일을 Inclass에 제출하시면 점수를 확인할 수 있습니다.\n",
        "\n",
        "여러분의 모델의 추론 결과로 나온 문서 당 세 개의 요약 인덱스에 해당하는 \"idx_#\"을 1로 채워 제출 파일을 만듭니다(현재는 아래 보시는 바와 같이 모두 0으로 채워져 있습니다). ID 값을 기준으로 채점을 진행하는 점 유의해주시기 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dlvE85eSemrR",
        "outputId": "c6c0ffa8-a9eb-4cfc-ea7c-e8d213b75295"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>summary_index1</th>\n",
              "      <th>summary_index2</th>\n",
              "      <th>summary_index3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79095</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>204506</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>142079</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>110816</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>207249</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  summary_index1  summary_index2  summary_index3\n",
              "0   79095               0               1               2\n",
              "1  204506               0               1               2\n",
              "2  142079               0               1               2\n",
              "3  110816               0               1               2\n",
              "4  207249               0               1               2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "submit = pd.read_csv(os.path.join(DATA_DIR,'sample_submission.csv'))\n",
        "submit.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Tir-zxUIemrR"
      },
      "outputs": [],
      "source": [
        "# 테스트 데이터셋 클래스 정의\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\" CustomDataset과 비슷한 구조이지만 레이블이 주어지지 않음을 염두 \"\"\"\n",
        "\n",
        "    def __init__(self, data_dir, mode):\n",
        "        self.data_dir = data_dir\n",
        "        self.mode = mode\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
        "        self.inputs = self.data_loader()\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading ' + self.mode + ' dataset..')\n",
        "        if os.path.isfile(os.path.join(self.data_dir, self.mode+'_X.pt')):\n",
        "            # torch tensor 불러오기\n",
        "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
        "        else:\n",
        "            # json 파일 불러오기\n",
        "            file_path = os.path.join(self.data_dir, self.mode + '.json')\n",
        "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
        "            inputs = pd.DataFrame(columns=['src'])\n",
        "            inputs['src'] =  df['article_original']\n",
        "      \n",
        "            # 전처리\n",
        "            inputs = self.preprocessing(inputs)\n",
        "            \n",
        "            # 다음부터는 전처리 과정을 반복하지 않기 위해 tensor 저장\n",
        "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
        "\n",
        "        inputs = inputs.values\n",
        "\n",
        "        return inputs\n",
        "\n",
        "    def pad(self, data, pad_id, max_len):\n",
        "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
        "        return padded_data\n",
        "\n",
        "    def preprocessing(self, inputs):\n",
        "        print('Preprocessing ' + self.mode + ' dataset..')\n",
        "        \n",
        "        #Encoding original text\n",
        "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
        "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
        "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
        "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
        "\n",
        "        ##Padding\n",
        "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
        "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
        "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
        "        inputs['segs'] = self.pad(inputs.segs, 0, max_encoding_len)\n",
        "        inputs['clss'] = self.pad(inputs.clss, -1, max_label_len)\n",
        "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
        "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
        "     \n",
        "        return inputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return [self.inputs[index][i] for i in range(5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIG2Pui_emrS",
        "outputId": "6a57b5a7-4cc5-4f74-dbae-b4023fccd75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test dataset..\n",
            "Preprocessing test dataset..\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터 로드\n",
        "test_dataset = TestDataset(data_dir=DATA_DIR, mode = 'test')\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtESxi9YemrS",
        "outputId": "7bba9d9b-2195-4eb8-b893-e135a1b6bb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0/376 completed\n",
            "Prediction: 150/376 completed\n",
            "Prediction: 300/376 completed\n",
            "Prediction all completed\n"
          ]
        }
      ],
      "source": [
        "\"\"\" 이전에 학습한 모델 weight파일을 불러 추론하려면 아래 주석을 풀고 실행\n",
        "    학습 진행 후 바로 추론하는 경우 학습 과정의 model 사용 (주석 풀지 않고 실행) \"\"\"\n",
        "MODEL_DIR = os.path.join(MODEL_DIR, 'best.pt')\n",
        "model = Summarizer().to(DEVICE)\n",
        "model.load_state_dict(torch.load(MODEL_DIR)['model'])\n",
        "\n",
        "# 추론\n",
        "model.eval()\n",
        "\n",
        "# 추론 결과를 pred 리스트로 저장할 예정\n",
        "pred_lst = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_index, (data) in enumerate(test_dataloader):\n",
        "        src = data[0].to(DEVICE)\n",
        "        clss = data[1].to(DEVICE)\n",
        "        segs = data[2].to(DEVICE)\n",
        "        mask = data[3].to(DEVICE)\n",
        "        mask_clss = data[4].to(DEVICE)\n",
        "        sent_score = model(src, segs, clss, mask, mask_clss)\n",
        "        pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
        "            \n",
        "        # 진행과정 출력\n",
        "        if batch_index % 150 == 0:\n",
        "            print(f'Prediction: {batch_index}/{len(test_dataloader)} completed')\n",
        "    print(\"Prediction all completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5R0oUTRemrS",
        "outputId": "3151e147-c8a1-491f-e90c-ee0a623834e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 5, 2],\n",
              " [9, 7, 0],\n",
              " [13, 8, 6],\n",
              " [9, 0, 7],\n",
              " [4, 3, 0],\n",
              " [0, 5, 4],\n",
              " [8, 7, 1],\n",
              " [5, 1, 4],\n",
              " [3, 4, 1],\n",
              " [3, 0, 1],\n",
              " [9, 5, 6],\n",
              " [1, 2, 4],\n",
              " [3, 2, 0],\n",
              " [3, 5, 2],\n",
              " [1, 0, 4],\n",
              " [4, 1, 3],\n",
              " [2, 3, 0],\n",
              " [10, 0, 9],\n",
              " [10, 0, 6],\n",
              " [0, 1, 6],\n",
              " [3, 0, 2],\n",
              " [16, 11, 15],\n",
              " [3, 1, 2],\n",
              " [8, 2, 0],\n",
              " [3, 0, 2],\n",
              " [4, 0, 5],\n",
              " [3, 0, 1],\n",
              " [12, 11, 1],\n",
              " [7, 9, 8],\n",
              " [0, 8, 5],\n",
              " [2, 4, 1],\n",
              " [5, 12, 11],\n",
              " [13, 28, 12],\n",
              " [0, 6, 5],\n",
              " [1, 3, 0],\n",
              " [4, 1, 0],\n",
              " [4, 0, 2],\n",
              " [4, 2, 0],\n",
              " [0, 2, 1],\n",
              " [18, 8, 3],\n",
              " [7, 4, 0],\n",
              " [15, 10, 12],\n",
              " [25, 0, 14],\n",
              " [4, 1, 3],\n",
              " [7, 12, 4],\n",
              " [4, 0, 1],\n",
              " [12, 6, 11],\n",
              " [20, 18, 17],\n",
              " [4, 0, 3],\n",
              " [12, 8, 7],\n",
              " [8, 3, 5],\n",
              " [3, 2, 0],\n",
              " [4, 2, 1],\n",
              " [14, 20, 16],\n",
              " [5, 3, 0],\n",
              " [0, 2, 1],\n",
              " [3, 2, 0],\n",
              " [4, 5, 2],\n",
              " [4, 1, 2],\n",
              " [6, 4, 0],\n",
              " [17, 8, 12],\n",
              " [0, 1, 3],\n",
              " [9, 7, 4],\n",
              " [5, 4, 3],\n",
              " [2, 3, 0],\n",
              " [3, 0, 1],\n",
              " [12, 13, 3],\n",
              " [8, 4, 3],\n",
              " [17, 11, 8],\n",
              " [4, 5, 3],\n",
              " [10, 1, 7],\n",
              " [5, 0, 2],\n",
              " [4, 5, 0],\n",
              " [5, 0, 4],\n",
              " [3, 6, 2],\n",
              " [12, 11, 8],\n",
              " [3, 0, 1],\n",
              " [3, 0, 2],\n",
              " [8, 7, 0],\n",
              " [3, 0, 1],\n",
              " [6, 4, 1],\n",
              " [18, 7, 17],\n",
              " [4, 2, 1],\n",
              " [4, 3, 5],\n",
              " [3, 5, 0],\n",
              " [10, 12, 11],\n",
              " [5, 0, 2],\n",
              " [4, 9, 0],\n",
              " [1, 5, 9],\n",
              " [3, 1, 0],\n",
              " [7, 3, 5],\n",
              " [13, 11, 2],\n",
              " [6, 5, 1],\n",
              " [6, 5, 7],\n",
              " [3, 0, 2],\n",
              " [3, 0, 2],\n",
              " [0, 1, 4],\n",
              " [16, 23, 17],\n",
              " [17, 5, 13],\n",
              " [6, 0, 5],\n",
              " [3, 0, 1],\n",
              " [3, 0, 2],\n",
              " [5, 2, 0],\n",
              " [3, 0, 2],\n",
              " [5, 10, 0],\n",
              " [3, 6, 5],\n",
              " [5, 4, 2],\n",
              " [2, 11, 9],\n",
              " [4, 8, 0],\n",
              " [5, 8, 0],\n",
              " [4, 1, 2],\n",
              " [3, 1, 0],\n",
              " [6, 4, 3],\n",
              " [0, 6, 1],\n",
              " [15, 0, 4],\n",
              " [11, 4, 6],\n",
              " [10, 0, 3],\n",
              " [3, 4, 1],\n",
              " [5, 4, 0],\n",
              " [17, 4, 18],\n",
              " [2, 3, 0],\n",
              " [0, 9, 6],\n",
              " [8, 0, 5],\n",
              " [3, 0, 6],\n",
              " [5, 0, 4],\n",
              " [4, 0, 1],\n",
              " [3, 0, 2],\n",
              " [6, 1, 5],\n",
              " [16, 13, 5],\n",
              " [16, 3, 7],\n",
              " [6, 2, 5],\n",
              " [6, 0, 3],\n",
              " [10, 0, 6],\n",
              " [21, 7, 9],\n",
              " [13, 6, 9],\n",
              " [10, 5, 14],\n",
              " [2, 3, 0],\n",
              " [15, 11, 12],\n",
              " [5, 3, 4],\n",
              " [3, 2, 8],\n",
              " [21, 20, 10],\n",
              " [11, 6, 4],\n",
              " [5, 8, 3],\n",
              " [0, 5, 1],\n",
              " [2, 3, 0],\n",
              " [5, 3, 1],\n",
              " [9, 4, 1],\n",
              " [12, 6, 10],\n",
              " [6, 2, 0],\n",
              " [13, 14, 12],\n",
              " [6, 2, 4],\n",
              " [13, 7, 9],\n",
              " [19, 16, 13],\n",
              " [4, 0, 2],\n",
              " [12, 11, 9],\n",
              " [4, 3, 0],\n",
              " [12, 4, 7],\n",
              " [3, 2, 0],\n",
              " [4, 5, 0],\n",
              " [0, 4, 1],\n",
              " [3, 2, 1],\n",
              " [5, 4, 0],\n",
              " [8, 0, 6],\n",
              " [4, 1, 2],\n",
              " [12, 7, 5],\n",
              " [10, 6, 5],\n",
              " [3, 1, 2],\n",
              " [16, 15, 14],\n",
              " [10, 4, 5],\n",
              " [4, 0, 3],\n",
              " [6, 9, 3],\n",
              " [8, 0, 9],\n",
              " [6, 5, 3],\n",
              " [3, 0, 4],\n",
              " [0, 5, 4],\n",
              " [7, 9, 5],\n",
              " [0, 2, 5],\n",
              " [7, 15, 18],\n",
              " [3, 0, 1],\n",
              " [10, 9, 5],\n",
              " [4, 3, 2],\n",
              " [3, 4, 5],\n",
              " [18, 8, 4],\n",
              " [0, 2, 4],\n",
              " [3, 0, 2],\n",
              " [4, 2, 3],\n",
              " [4, 0, 3],\n",
              " [8, 6, 7],\n",
              " [5, 3, 2],\n",
              " [5, 3, 9],\n",
              " [15, 0, 10],\n",
              " [14, 22, 26],\n",
              " [3, 0, 1],\n",
              " [3, 2, 0],\n",
              " [10, 6, 5],\n",
              " [7, 10, 4],\n",
              " [8, 6, 3],\n",
              " [12, 4, 9],\n",
              " [10, 4, 16],\n",
              " [8, 1, 6],\n",
              " [3, 2, 0],\n",
              " [12, 9, 0],\n",
              " [3, 5, 4],\n",
              " [3, 1, 2],\n",
              " [3, 0, 2],\n",
              " [5, 2, 3],\n",
              " [8, 1, 7],\n",
              " [6, 2, 4],\n",
              " [39, 41, 0],\n",
              " [4, 2, 0],\n",
              " [7, 26, 6],\n",
              " [3, 0, 2],\n",
              " [3, 0, 1],\n",
              " [11, 6, 0],\n",
              " [4, 3, 2],\n",
              " [12, 9, 10],\n",
              " [5, 4, 2],\n",
              " [13, 0, 7],\n",
              " [9, 3, 0],\n",
              " [5, 4, 0],\n",
              " [12, 1, 0],\n",
              " [15, 6, 3],\n",
              " [8, 2, 6],\n",
              " [4, 0, 5],\n",
              " [12, 0, 10],\n",
              " [4, 0, 2],\n",
              " [5, 2, 4],\n",
              " [16, 5, 15],\n",
              " [3, 0, 1],\n",
              " [7, 1, 16],\n",
              " [3, 4, 0],\n",
              " [6, 0, 4],\n",
              " [4, 2, 9],\n",
              " [3, 1, 2],\n",
              " [2, 0, 3],\n",
              " [6, 7, 8],\n",
              " [16, 3, 15],\n",
              " [5, 0, 2],\n",
              " [7, 20, 3],\n",
              " [4, 1, 2],\n",
              " [4, 1, 2],\n",
              " [3, 2, 1],\n",
              " [6, 1, 5],\n",
              " [6, 3, 1],\n",
              " [11, 6, 13],\n",
              " [6, 0, 5],\n",
              " [2, 3, 1],\n",
              " [5, 3, 2],\n",
              " [5, 3, 4],\n",
              " [6, 4, 3],\n",
              " [1, 5, 0],\n",
              " [3, 0, 2],\n",
              " [3, 4, 2],\n",
              " [6, 4, 0],\n",
              " [4, 3, 0],\n",
              " [2, 1, 0],\n",
              " [6, 3, 0],\n",
              " [8, 5, 0],\n",
              " [6, 2, 4],\n",
              " [13, 0, 11],\n",
              " [2, 3, 0],\n",
              " [10, 6, 1],\n",
              " [7, 28, 22],\n",
              " [10, 6, 12],\n",
              " [4, 0, 3],\n",
              " [4, 2, 0],\n",
              " [0, 6, 5],\n",
              " [5, 2, 1],\n",
              " [0, 2, 6],\n",
              " [8, 19, 20],\n",
              " [5, 0, 4],\n",
              " [7, 9, 3],\n",
              " [11, 10, 2],\n",
              " [11, 5, 10],\n",
              " [9, 4, 1],\n",
              " [6, 4, 2],\n",
              " [6, 3, 5],\n",
              " [9, 5, 0],\n",
              " [5, 3, 1],\n",
              " [8, 1, 5],\n",
              " [3, 0, 2],\n",
              " [8, 7, 2],\n",
              " [6, 2, 3],\n",
              " [6, 3, 0],\n",
              " [6, 0, 5],\n",
              " [22, 9, 12],\n",
              " [6, 1, 4],\n",
              " [3, 0, 1],\n",
              " [11, 12, 1],\n",
              " [1, 4, 3],\n",
              " [11, 0, 6],\n",
              " [11, 10, 0],\n",
              " [6, 0, 5],\n",
              " [6, 0, 5],\n",
              " [8, 1, 5],\n",
              " [4, 1, 0],\n",
              " [10, 8, 9],\n",
              " [5, 0, 4],\n",
              " [16, 2, 8],\n",
              " [4, 2, 1],\n",
              " [2, 3, 1],\n",
              " [15, 2, 13],\n",
              " [3, 0, 2],\n",
              " [4, 3, 2],\n",
              " [3, 0, 2],\n",
              " [14, 6, 8],\n",
              " [15, 6, 1],\n",
              " [11, 1, 3],\n",
              " [13, 7, 14],\n",
              " [3, 7, 0],\n",
              " [5, 2, 4],\n",
              " [0, 3, 2],\n",
              " [9, 0, 8],\n",
              " [10, 20, 21],\n",
              " [4, 0, 3],\n",
              " [4, 3, 0],\n",
              " [1, 2, 3],\n",
              " [4, 5, 1],\n",
              " [12, 7, 10],\n",
              " [3, 2, 1],\n",
              " [10, 15, 14],\n",
              " [11, 2, 4],\n",
              " [8, 0, 2],\n",
              " [0, 5, 3],\n",
              " [4, 0, 3],\n",
              " [4, 0, 1],\n",
              " [10, 3, 1],\n",
              " [0, 9, 5],\n",
              " [10, 5, 3],\n",
              " [4, 3, 1],\n",
              " [3, 1, 2],\n",
              " [4, 0, 2],\n",
              " [2, 3, 0],\n",
              " [3, 0, 2],\n",
              " [11, 45, 10],\n",
              " [0, 3, 1],\n",
              " [3, 2, 0],\n",
              " [0, 3, 1],\n",
              " [2, 3, 0],\n",
              " [2, 1, 3],\n",
              " [5, 0, 2],\n",
              " [5, 3, 1],\n",
              " [3, 4, 0],\n",
              " [0, 3, 2],\n",
              " [13, 3, 2],\n",
              " [0, 24, 21],\n",
              " [6, 2, 4],\n",
              " [7, 8, 12],\n",
              " [5, 1, 4],\n",
              " [11, 0, 5],\n",
              " [0, 3, 2],\n",
              " [8, 4, 0],\n",
              " [3, 2, 0],\n",
              " [4, 3, 2],\n",
              " [2, 9, 5],\n",
              " [4, 0, 2],\n",
              " [5, 3, 4],\n",
              " [14, 7, 12],\n",
              " [0, 3, 2],\n",
              " [5, 4, 0],\n",
              " [5, 0, 4],\n",
              " [24, 0, 8],\n",
              " [15, 2, 5],\n",
              " [9, 0, 7],\n",
              " [19, 10, 18],\n",
              " [8, 5, 6],\n",
              " [23, 14, 13],\n",
              " [3, 0, 1],\n",
              " [0, 4, 2],\n",
              " [11, 15, 23],\n",
              " [5, 1, 2],\n",
              " [8, 6, 5],\n",
              " [5, 4, 3],\n",
              " [4, 15, 0],\n",
              " [19, 13, 3],\n",
              " [8, 11, 1],\n",
              " [5, 2, 3],\n",
              " [14, 5, 9],\n",
              " [9, 1, 4],\n",
              " [19, 16, 20],\n",
              " [3, 0, 2],\n",
              " [35, 34, 19],\n",
              " [10, 8, 9],\n",
              " [11, 8, 1],\n",
              " [8, 0, 5],\n",
              " [0, 1, 2],\n",
              " [25, 24, 0],\n",
              " [9, 4, 0],\n",
              " [5, 0, 9],\n",
              " [15, 14, 10],\n",
              " [6, 5, 7],\n",
              " [6, 5, 0],\n",
              " [2, 3, 1],\n",
              " [0, 1, 2],\n",
              " [3, 0, 1],\n",
              " [4, 1, 2],\n",
              " [8, 2, 1],\n",
              " [0, 1, 4],\n",
              " [9, 6, 12],\n",
              " [4, 1, 3],\n",
              " [4, 3, 0],\n",
              " [21, 22, 8],\n",
              " [0, 2, 1],\n",
              " [4, 2, 0],\n",
              " [31, 9, 12],\n",
              " [29, 3, 13],\n",
              " [0, 1, 3],\n",
              " [0, 3, 2],\n",
              " [13, 4, 8],\n",
              " [6, 0, 4],\n",
              " [4, 0, 1],\n",
              " [5, 1, 0],\n",
              " [5, 0, 2],\n",
              " [15, 14, 2],\n",
              " [3, 2, 1],\n",
              " [12, 4, 8],\n",
              " [3, 2, 0],\n",
              " [2, 3, 0],\n",
              " [4, 2, 0],\n",
              " [1, 3, 0],\n",
              " [4, 0, 2],\n",
              " [6, 0, 3],\n",
              " [8, 2, 3],\n",
              " [10, 2, 7],\n",
              " [2, 3, 0],\n",
              " [3, 0, 2],\n",
              " [8, 0, 7],\n",
              " [3, 0, 1],\n",
              " [5, 0, 6],\n",
              " [8, 9, 5],\n",
              " [6, 4, 1],\n",
              " [5, 0, 3],\n",
              " [0, 3, 1],\n",
              " [3, 2, 0],\n",
              " [32, 31, 30],\n",
              " [9, 10, 15],\n",
              " [10, 0, 8],\n",
              " [4, 8, 1],\n",
              " [13, 1, 0],\n",
              " [3, 2, 1],\n",
              " [4, 0, 2],\n",
              " [4, 0, 3],\n",
              " [3, 2, 1],\n",
              " [0, 3, 1],\n",
              " [3, 0, 1],\n",
              " [9, 8, 7],\n",
              " [3, 2, 1],\n",
              " [4, 0, 3],\n",
              " [9, 6, 1],\n",
              " [4, 7, 6],\n",
              " [15, 14, 6],\n",
              " [5, 4, 3],\n",
              " [3, 1, 0],\n",
              " [5, 0, 2],\n",
              " [32, 20, 0],\n",
              " [3, 1, 0],\n",
              " [3, 1, 0],\n",
              " [6, 4, 5],\n",
              " [3, 0, 2],\n",
              " [9, 7, 4],\n",
              " [4, 1, 0],\n",
              " [5, 0, 2],\n",
              " [3, 1, 2],\n",
              " [0, 2, 4],\n",
              " [11, 12, 2],\n",
              " [10, 6, 3],\n",
              " [2, 17, 13],\n",
              " [9, 10, 7],\n",
              " [3, 8, 0],\n",
              " [0, 1, 5],\n",
              " [10, 0, 9],\n",
              " [13, 5, 1],\n",
              " [3, 0, 1],\n",
              " [20, 17, 16],\n",
              " [3, 4, 0],\n",
              " [9, 11, 0],\n",
              " [3, 5, 0],\n",
              " [3, 0, 2],\n",
              " [6, 8, 7],\n",
              " [6, 4, 1],\n",
              " [4, 0, 2],\n",
              " [2, 15, 10],\n",
              " [0, 3, 1],\n",
              " [11, 10, 8],\n",
              " [4, 1, 2],\n",
              " [20, 18, 4],\n",
              " [9, 0, 1],\n",
              " [9, 7, 8],\n",
              " [3, 0, 1],\n",
              " [21, 12, 20],\n",
              " [3, 0, 1],\n",
              " [10, 0, 1],\n",
              " [11, 1, 0],\n",
              " [0, 3, 2],\n",
              " [16, 4, 12],\n",
              " [8, 1, 3],\n",
              " [6, 3, 7],\n",
              " [3, 0, 4],\n",
              " [26, 16, 0],\n",
              " [3, 2, 1],\n",
              " [5, 6, 3],\n",
              " [3, 4, 1],\n",
              " [11, 10, 5],\n",
              " [4, 3, 0],\n",
              " [12, 27, 6],\n",
              " [12, 3, 2],\n",
              " [4, 7, 3],\n",
              " [9, 7, 6],\n",
              " [4, 6, 3],\n",
              " [11, 4, 0],\n",
              " [2, 3, 1],\n",
              " [33, 0, 20],\n",
              " [6, 1, 3],\n",
              " [6, 1, 5],\n",
              " [1, 3, 2],\n",
              " [3, 2, 0],\n",
              " [0, 1, 3],\n",
              " [20, 0, 5],\n",
              " [11, 1, 6],\n",
              " [7, 8, 6],\n",
              " [5, 0, 3],\n",
              " [5, 3, 4],\n",
              " [9, 8, 4],\n",
              " [8, 7, 1],\n",
              " [9, 12, 4],\n",
              " [3, 2, 1],\n",
              " [3, 1, 0],\n",
              " [7, 8, 6],\n",
              " [2, 0, 3],\n",
              " [7, 14, 11],\n",
              " [8, 0, 1],\n",
              " [4, 7, 0],\n",
              " [8, 7, 3],\n",
              " [11, 9, 1],\n",
              " [3, 4, 1],\n",
              " [5, 0, 2],\n",
              " [10, 7, 1],\n",
              " [9, 8, 3],\n",
              " [4, 2, 1],\n",
              " [8, 1, 0],\n",
              " [5, 4, 0],\n",
              " [18, 17, 7],\n",
              " [2, 11, 0],\n",
              " [30, 17, 14],\n",
              " [13, 4, 5],\n",
              " [4, 2, 1],\n",
              " [3, 5, 1],\n",
              " [3, 2, 5],\n",
              " [3, 0, 1],\n",
              " [6, 9, 5],\n",
              " [3, 2, 1],\n",
              " [6, 2, 8],\n",
              " [4, 0, 1],\n",
              " [4, 2, 0],\n",
              " [8, 13, 3],\n",
              " [2, 3, 1],\n",
              " [8, 2, 4],\n",
              " [6, 0, 5],\n",
              " [9, 10, 11],\n",
              " [8, 2, 3],\n",
              " [4, 3, 0],\n",
              " [4, 3, 1],\n",
              " [18, 7, 19],\n",
              " [14, 13, 8],\n",
              " [15, 11, 12],\n",
              " [4, 3, 1],\n",
              " [20, 16, 0],\n",
              " [9, 11, 8],\n",
              " [10, 3, 6],\n",
              " [9, 8, 3],\n",
              " [8, 10, 7],\n",
              " [3, 0, 2],\n",
              " [3, 0, 2],\n",
              " [13, 4, 5],\n",
              " [8, 7, 0],\n",
              " [4, 0, 2],\n",
              " [9, 1, 8],\n",
              " [12, 0, 4],\n",
              " [14, 10, 12],\n",
              " [4, 8, 1],\n",
              " [3, 0, 1],\n",
              " [2, 0, 5],\n",
              " [3, 2, 0],\n",
              " [10, 7, 6],\n",
              " [9, 3, 5],\n",
              " [8, 2, 4],\n",
              " [3, 16, 9],\n",
              " [11, 0, 1],\n",
              " [5, 8, 11],\n",
              " [28, 29, 27],\n",
              " [17, 16, 7],\n",
              " [18, 17, 0],\n",
              " [2, 4, 0],\n",
              " [8, 7, 1],\n",
              " [3, 2, 0],\n",
              " [10, 9, 4],\n",
              " [8, 7, 6],\n",
              " [24, 9, 2],\n",
              " [6, 1, 5],\n",
              " [2, 3, 1],\n",
              " [14, 8, 16],\n",
              " [13, 7, 12],\n",
              " [4, 0, 2],\n",
              " [3, 1, 2],\n",
              " [4, 3, 1],\n",
              " [11, 0, 9],\n",
              " [6, 5, 0],\n",
              " [10, 7, 5],\n",
              " [1, 2, 0],\n",
              " [2, 1, 31],\n",
              " [16, 11, 12],\n",
              " [2, 3, 5],\n",
              " [4, 2, 0],\n",
              " [3, 1, 4],\n",
              " [10, 4, 0],\n",
              " [3, 5, 0],\n",
              " [15, 11, 13],\n",
              " [4, 5, 0],\n",
              " [4, 2, 0],\n",
              " [9, 6, 4],\n",
              " [4, 2, 1],\n",
              " [4, 0, 3],\n",
              " [10, 0, 9],\n",
              " [2, 19, 1],\n",
              " [18, 8, 3],\n",
              " [4, 3, 0],\n",
              " [11, 10, 3],\n",
              " [5, 0, 4],\n",
              " [18, 3, 4],\n",
              " [4, 3, 0],\n",
              " [5, 4, 0],\n",
              " [3, 0, 1],\n",
              " [5, 2, 0],\n",
              " [10, 3, 6],\n",
              " [7, 11, 8],\n",
              " [8, 2, 5],\n",
              " [13, 10, 6],\n",
              " [4, 1, 3],\n",
              " [6, 2, 4],\n",
              " [5, 3, 1],\n",
              " [1, 5, 0],\n",
              " [7, 4, 2],\n",
              " [6, 0, 3],\n",
              " [3, 1, 2],\n",
              " [16, 4, 2],\n",
              " [2, 0, 3],\n",
              " [2, 3, 0],\n",
              " [19, 12, 9],\n",
              " [3, 0, 1],\n",
              " [8, 3, 1],\n",
              " [4, 2, 3],\n",
              " [15, 9, 7],\n",
              " [3, 2, 1],\n",
              " [0, 3, 4],\n",
              " [11, 5, 4],\n",
              " [6, 4, 1],\n",
              " [10, 9, 11],\n",
              " [4, 5, 1],\n",
              " [9, 5, 0],\n",
              " [5, 3, 4],\n",
              " [3, 2, 1],\n",
              " [11, 12, 9],\n",
              " [3, 1, 0],\n",
              " [3, 0, 6],\n",
              " [4, 3, 13],\n",
              " [15, 0, 6],\n",
              " [6, 3, 4],\n",
              " [4, 2, 1],\n",
              " [6, 3, 5],\n",
              " [5, 3, 4],\n",
              " [4, 3, 2],\n",
              " [8, 1, 3],\n",
              " [11, 4, 3],\n",
              " [12, 5, 2],\n",
              " [4, 2, 3],\n",
              " [11, 9, 8],\n",
              " [6, 4, 0],\n",
              " [4, 3, 2],\n",
              " [3, 0, 2],\n",
              " [10, 5, 7],\n",
              " [13, 11, 12],\n",
              " [4, 0, 2],\n",
              " [9, 6, 2],\n",
              " [18, 15, 7],\n",
              " [2, 0, 3],\n",
              " [6, 5, 9],\n",
              " [3, 1, 2],\n",
              " [12, 8, 3],\n",
              " [7, 6, 11],\n",
              " [5, 1, 4],\n",
              " [11, 4, 10],\n",
              " [9, 4, 1],\n",
              " [9, 2, 0],\n",
              " [11, 10, 3],\n",
              " [4, 0, 2],\n",
              " [4, 0, 3],\n",
              " [10, 15, 5],\n",
              " [8, 4, 0],\n",
              " [9, 8, 7],\n",
              " [6, 4, 5],\n",
              " [4, 0, 1],\n",
              " [20, 12, 13],\n",
              " [9, 8, 2],\n",
              " [2, 4, 1],\n",
              " [27, 30, 5],\n",
              " [5, 10, 9],\n",
              " [3, 0, 1],\n",
              " [3, 0, 2],\n",
              " [11, 23, 22],\n",
              " [1, 4, 0],\n",
              " [3, 1, 2],\n",
              " [12, 5, 6],\n",
              " [23, 12, 21],\n",
              " [6, 5, 1],\n",
              " [6, 5, 0],\n",
              " [15, 14, 2],\n",
              " [3, 0, 2],\n",
              " [3, 1, 2],\n",
              " [11, 6, 7],\n",
              " [7, 8, 5],\n",
              " [3, 0, 1],\n",
              " [20, 19, 0],\n",
              " [4, 1, 3],\n",
              " [2, 5, 1],\n",
              " [15, 5, 1],\n",
              " [6, 9, 4],\n",
              " [8, 7, 2],\n",
              " [22, 14, 13],\n",
              " [26, 25, 24],\n",
              " [9, 4, 0],\n",
              " [3, 0, 6],\n",
              " [6, 5, 2],\n",
              " [3, 1, 0],\n",
              " [31, 30, 16],\n",
              " [19, 0, 4],\n",
              " [2, 3, 0],\n",
              " [9, 5, 10],\n",
              " [6, 3, 0],\n",
              " [4, 0, 8],\n",
              " [3, 0, 2],\n",
              " [3, 1, 0],\n",
              " [6, 1, 9],\n",
              " [4, 2, 3],\n",
              " [2, 0, 3],\n",
              " [9, 10, 0],\n",
              " [3, 0, 2],\n",
              " [4, 2, 0],\n",
              " [3, 6, 0],\n",
              " [3, 8, 2],\n",
              " [6, 3, 5],\n",
              " [21, 8, 2],\n",
              " [4, 1, 2],\n",
              " [5, 3, 4],\n",
              " [5, 4, 3],\n",
              " [3, 0, 1],\n",
              " [3, 4, 0],\n",
              " [11, 15, 5],\n",
              " [3, 0, 2],\n",
              " [5, 3, 0],\n",
              " [9, 3, 2],\n",
              " [0, 9, 4],\n",
              " [21, 7, 19],\n",
              " [12, 0, 1],\n",
              " [3, 0, 2],\n",
              " [4, 1, 3],\n",
              " [4, 3, 2],\n",
              " [11, 5, 10],\n",
              " [3, 1, 2],\n",
              " [11, 1, 4],\n",
              " [9, 11, 2],\n",
              " [36, 35, 18],\n",
              " [10, 0, 5],\n",
              " [5, 4, 0],\n",
              " [2, 5, 0],\n",
              " [4, 5, 1],\n",
              " [12, 21, 18],\n",
              " [2, 5, 0],\n",
              " [12, 0, 11],\n",
              " [10, 8, 0],\n",
              " [6, 3, 0],\n",
              " [13, 12, 3],\n",
              " [6, 0, 1],\n",
              " [3, 2, 1],\n",
              " [9, 0, 7],\n",
              " [3, 0, 2],\n",
              " [3, 0, 8],\n",
              " [9, 0, 7],\n",
              " [9, 5, 1],\n",
              " [5, 9, 2],\n",
              " [3, 2, 0],\n",
              " [15, 10, 0],\n",
              " [9, 6, 2],\n",
              " [5, 3, 4],\n",
              " [6, 0, 4],\n",
              " [4, 1, 0],\n",
              " [3, 2, 0],\n",
              " [5, 4, 1],\n",
              " [0, 1, 3],\n",
              " [8, 5, 0],\n",
              " [3, 1, 2],\n",
              " [17, 11, 16],\n",
              " [0, 1, 5],\n",
              " [3, 0, 2],\n",
              " [3, 2, 0],\n",
              " [9, 0, 6],\n",
              " [4, 9, 2],\n",
              " [1, 0, 2],\n",
              " [8, 6, 4],\n",
              " [9, 7, 2],\n",
              " [10, 2, 1],\n",
              " [3, 0, 2],\n",
              " [3, 4, 2],\n",
              " [6, 3, 0],\n",
              " [4, 3, 1],\n",
              " [0, 6, 9],\n",
              " [14, 13, 11],\n",
              " [3, 2, 4],\n",
              " [5, 0, 1],\n",
              " [1, 0, 2],\n",
              " [5, 0, 1],\n",
              " [18, 3, 6],\n",
              " [2, 3, 0],\n",
              " [20, 21, 17],\n",
              " [10, 7, 8],\n",
              " [5, 4, 1],\n",
              " [12, 8, 1],\n",
              " [10, 6, 3],\n",
              " [5, 3, 0],\n",
              " [0, 2, 4],\n",
              " [5, 0, 2],\n",
              " [3, 6, 0],\n",
              " [0, 2, 4],\n",
              " [17, 6, 11],\n",
              " [9, 11, 10],\n",
              " [3, 2, 1],\n",
              " [10, 7, 9],\n",
              " [3, 1, 0],\n",
              " [17, 13, 4],\n",
              " [11, 9, 10],\n",
              " [2, 3, 4],\n",
              " [3, 1, 0],\n",
              " [8, 9, 0],\n",
              " [3, 0, 2],\n",
              " [9, 7, 2],\n",
              " [10, 0, 5],\n",
              " [18, 11, 10],\n",
              " [6, 2, 10],\n",
              " [3, 5, 0],\n",
              " [6, 9, 1],\n",
              " [26, 8, 4],\n",
              " [9, 15, 7],\n",
              " [4, 3, 1],\n",
              " [4, 3, 2],\n",
              " [13, 14, 0],\n",
              " [4, 2, 0],\n",
              " [5, 1, 2],\n",
              " [9, 6, 5],\n",
              " [8, 6, 0],\n",
              " [4, 3, 0],\n",
              " [4, 0, 2],\n",
              " [5, 9, 4],\n",
              " [11, 15, 24],\n",
              " [9, 8, 6],\n",
              " [0, 2, 3],\n",
              " [8, 7, 0],\n",
              " [4, 6, 2],\n",
              " [3, 0, 2],\n",
              " [7, 1, 8],\n",
              " [5, 3, 1],\n",
              " [1, 2, 0],\n",
              " [0, 4, 3],\n",
              " [5, 2, 3],\n",
              " [18, 11, 4],\n",
              " [9, 22, 14],\n",
              " [2, 5, 4],\n",
              " [5, 3, 0],\n",
              " [5, 11, 3],\n",
              " [3, 5, 0],\n",
              " [3, 2, 0],\n",
              " [3, 0, 2],\n",
              " [4, 2, 3],\n",
              " [5, 6, 4],\n",
              " [1, 6, 3],\n",
              " [6, 5, 0],\n",
              " [5, 8, 0],\n",
              " [5, 8, 1],\n",
              " [7, 6, 16],\n",
              " [3, 0, 1],\n",
              " [3, 0, 1],\n",
              " [12, 0, 7],\n",
              " [3, 4, 5],\n",
              " [3, 2, 0],\n",
              " [12, 10, 2],\n",
              " [12, 1, 6],\n",
              " [4, 0, 3],\n",
              " [4, 0, 2],\n",
              " [4, 1, 2],\n",
              " [5, 4, 0],\n",
              " [1, 12, 5],\n",
              " [5, 8, 3],\n",
              " [2, 0, 1],\n",
              " [9, 8, 1],\n",
              " [3, 0, 2],\n",
              " [13, 15, 19],\n",
              " [2, 3, 1],\n",
              " [5, 1, 0],\n",
              " [0, 6, 1],\n",
              " [4, 1, 5],\n",
              " [5, 4, 0],\n",
              " [10, 5, 0],\n",
              " [8, 11, 6],\n",
              " [7, 10, 13],\n",
              " [8, 13, 7],\n",
              " [13, 12, 1],\n",
              " [5, 2, 4],\n",
              " [8, 3, 2],\n",
              " [4, 5, 1],\n",
              " [5, 2, 4],\n",
              " [5, 4, 3],\n",
              " [16, 4, 2],\n",
              " [3, 2, 1],\n",
              " [7, 4, 8],\n",
              " [4, 0, 1],\n",
              " [3, 4, 6],\n",
              " [4, 1, 3],\n",
              " [5, 0, 4],\n",
              " [4, 2, 3],\n",
              " [3, 0, 2],\n",
              " [0, 2, 4],\n",
              " [4, 6, 1],\n",
              " [5, 4, 3],\n",
              " [4, 0, 1],\n",
              " [3, 0, 1],\n",
              " [8, 7, 2],\n",
              " [10, 3, 11],\n",
              " [13, 6, 12],\n",
              " [17, 13, 8],\n",
              " [19, 8, 3],\n",
              " [5, 6, 7],\n",
              " [15, 7, 1],\n",
              " [5, 3, 1],\n",
              " [11, 5, 10],\n",
              " [2, 3, 4],\n",
              " [5, 0, 4],\n",
              " [3, 0, 4],\n",
              " [6, 0, 3],\n",
              " [9, 7, 3],\n",
              " [15, 5, 0],\n",
              " [0, 8, 2],\n",
              " [4, 3, 1],\n",
              " [8, 7, 0],\n",
              " [3, 2, 1],\n",
              " [4, 6, 3],\n",
              " [5, 1, 4],\n",
              " [10, 6, 9],\n",
              " [9, 10, 13],\n",
              " [21, 17, 3],\n",
              " [17, 10, 11],\n",
              " [20, 8, 22],\n",
              " [10, 5, 3],\n",
              " [38, 21, 0],\n",
              " [3, 0, 1],\n",
              " [4, 0, 1],\n",
              " [2, 3, 6],\n",
              " [2, 3, 4],\n",
              " [16, 5, 0],\n",
              " [5, 3, 4],\n",
              " [4, 3, 5],\n",
              " [3, 0, 1],\n",
              " [5, 2, 4],\n",
              " [3, 6, 0],\n",
              " [5, 3, 8],\n",
              " [0, 4, 3],\n",
              " [10, 14, 0],\n",
              " [3, 5, 0],\n",
              " [13, 12, 0],\n",
              " [8, 3, 5],\n",
              " [4, 1, 3],\n",
              " [10, 2, 0],\n",
              " [3, 0, 1],\n",
              " [3, 0, 2],\n",
              " [2, 3, 0],\n",
              " [4, 0, 3],\n",
              " [5, 0, 3],\n",
              " [2, 0, 4],\n",
              " [5, 2, 0],\n",
              " [6, 2, 5],\n",
              " [3, 1, 0],\n",
              " [3, 1, 2],\n",
              " [12, 1, 8],\n",
              " [19, 18, 3],\n",
              " [2, 17, 3],\n",
              " [8, 0, 6],\n",
              " [4, 3, 0],\n",
              " [8, 5, 0],\n",
              " [5, 2, 3],\n",
              " [6, 2, 3],\n",
              " [3, 0, 2],\n",
              " [22, 0, 37],\n",
              " [4, 2, 3],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "pred_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "GFUS1riiemrS",
        "outputId": "35a97ae3-4f3b-4a45-9e25-73f1bb1e4918"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>summary_index1</th>\n",
              "      <th>summary_index2</th>\n",
              "      <th>summary_index3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>83319</td>\n",
              "      <td>60</td>\n",
              "      <td>121</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID  summary_index1  summary_index2  summary_index3\n",
              "708  83319              60             121             117"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# 제출 파일\n",
        "for i,txt in enumerate(pred_lst):\n",
        "    submit.iloc[i, 1] += txt[0]+1\n",
        "    submit.iloc[i, 2] += txt[1]+1\n",
        "    submit.iloc[i, 3] += txt[2]+1\n",
        "    # print(submit.iloc[i, 1])\n",
        "submit[submit[\"ID\"] == 83319]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WM4WBBuRemrS"
      },
      "outputs": [],
      "source": [
        "submit.to_csv(os.path.join(ROOT_PATH, 'prediction.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "YFvILhRcemrS"
      },
      "outputs": [],
      "source": [
        "predc = pd.read_csv(\"./prediction.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predc[predc[\"ID\"] == 83319]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "57uOhrTN7Nra",
        "outputId": "1a647093-8e10-4bf3-dccf-df46f929163a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>summary_index1</th>\n",
              "      <th>summary_index2</th>\n",
              "      <th>summary_index3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>83319</td>\n",
              "      <td>60</td>\n",
              "      <td>121</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID  summary_index1  summary_index2  summary_index3\n",
              "708  83319              60             121             117"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-_4MPMIX7OeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "korean_nlp_legal_docs_torch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TensorFlow 2.7 on Python 3.8 & CUDA 11.3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}