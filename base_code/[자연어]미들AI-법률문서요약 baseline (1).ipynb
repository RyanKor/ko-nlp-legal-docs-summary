{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f4ceb0-e8c6-47f9-b316-3eb58f602d8c",
   "metadata": {},
   "source": [
    "# 자연어/놀이터/문서 요약\n",
    "\n",
    "이 노트북을 차례로 살펴보며 코드의 빈 곳을 채우며 실행하면 자연어 문서 요약 모델의 전반적인 과정을 수행해볼 수 있게 제작되었습니다.\n",
    "\n",
    "## 과제 설명\n",
    "법률 문서에 대한 원문을 가장 잘 나타내는 3개의 문장을 추출하는 문서 요약 모델 개발\n",
    "    \n",
    "### 데이터 설명\n",
    "- 입출력: \n",
    "    - 입력: 문장별로 나뉜 법률 문서 원문, 예) 법률 문서 = [문장1, 문장2, ..., 문장K], K : 문서 길이\n",
    "    - 출력: 요약문에 포함될 문장 인덱스 3개\n",
    "- 데이터셋 구성\n",
    "    - 학습 데이터:\n",
    "        - train.json : 24,027개의 법률 문서 아이디 (id), 원문 (article_original), 요약문 (extractive)\n",
    "    - 테스트 데이터:\n",
    "        - test.json : 3,004개의 법률 문서 아이디 (id), 원문 (article_original)\n",
    "\n",
    "### 사용 pretrained 모델\n",
    "- `beomi/KcELECTRA-base` [Documentation](https://github.com/Beomi/KcELECTRA)\n",
    "- [BERT모델 논문](https://arxiv.org/pdf/1810.04805.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a5476e-7964-426f-8377-9c4e9bfa6058",
   "metadata": {},
   "source": [
    "## 세팅\n",
    "### 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df8500-a541-456f-bdfb-babca58bfb80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 설치되지 않은 라이브러리의 경우, 주석 해제 후 코드를 실행하여 설치\n",
    "# !pip install pytorch-pretrained-bert\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396e3c9-bd48-4801-999a-46d0f1cba3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 및 코드 파일 불러오기\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a9e134-6adc-4559-9913-a19b1e6b09a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 기타\n",
    "  데이터는 현재 디렉토리의 `data/`폴더 안에 저장합니다.  \n",
    "- working directory 구조  \n",
    "  |--code.ipynb  \n",
    "  |--data/  \n",
    "  |--|--train/  \n",
    "  |--|--|--images/  \n",
    "  |--|--|--|--...  \n",
    "  |--|--|--labels.json  \n",
    "  |--|--test/  \n",
    "  |--|--|--images\n",
    "\n",
    "- 경로를 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd63e0-20d9-415b-932a-243e2ce70322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 경로 설정\n",
    "ROOT_PATH = ##### 코드와 데이터가 위치한 경로 지정 #####\n",
    "DATA_DIR = os.path.join(ROOT_PATH, 'data')\n",
    "MODEL_DIR = ##### 학습된 모델을 저장할 경로#####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1266aa5-6245-4afb-97f9-8d73584a3c6d",
   "metadata": {},
   "source": [
    "## 데이터 로드\n",
    "- hyper parameter를 지정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4fd14-faf7-43c3-b8d8-0795d9c537d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "TRAIN_BATCH_SIZE = ### 사용자 지정 ###\n",
    "EVAL_BATCH_SIZE = ### 사용자 지정 ###\n",
    "\n",
    "# 학습 데이터만 있으니 학습 데이터셋 비율과 validation 데이터셋 비율을 나누기 위해  (원하는 대로 조정 해보세요.)\n",
    "TRAIN_RATIO = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec497218-398e-4d2e-ab34-6071a5b969bf",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- 자연어 데이터를 전처리 하는 `preprocessing`에서 패딩을 실행하는 함수를 만들어보세요.  \n",
    "  (`##### 코드 #####` 부분)\n",
    "- `__init__` 에서 tokenizer는 transformers 라이브러리에서 AutoTokenizer를 사용합니다. 이 외에도 원하는 토크나이저를 적용해 다양한 실험을 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b56da-e358-4f4f-a008-bd7c5663c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "        self.inputs, self.labels = self.data_loader()\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        \n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode + '_X.pt')):\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            labels = torch.load(os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        else:\n",
    "            file_path = os.path.join(self.data_dir, 'train.json')\n",
    "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
    "          \n",
    "            if self.mode == 'train':\n",
    "                df = df.loc[:TRAIN_RATIO*int(len(df)), :]\n",
    "            elif self.mode == 'val':\n",
    "                df = df.loc[TRAIN_RATIO*int(len(df)):, :]\n",
    "\n",
    "            inputs = pd.DataFrame(columns=['src'])\n",
    "            labels = pd.DataFrame(columns=['trg'])\n",
    "            inputs['src'] =  df['article_original']\n",
    "            labels['trg'] =  df['extractive']\n",
    "          \n",
    "            # Preprocessing\n",
    "            inputs, labels = self.preprocessing(inputs, labels)\n",
    "            # Save data\n",
    "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            torch.save(labels, os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        inputs = inputs.values\n",
    "        labels = labels.values\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def pad(self, data, pad_id, max_len):\n",
    "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
    "        return padded_data\n",
    "\n",
    "    def preprocessing(self, inputs, labels):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        #Encoding original text\n",
    "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
    "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
    "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
    "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
    "\n",
    "        ##Padding\n",
    "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "        max_label_len = max(inputs.clss.map(lambda x: len(x))) \n",
    "        \n",
    "        # mask와 mask clss를 참고하여 0 혹은 -1로 패딩하세요\n",
    "        inputs['src'] = ##### 코드 #####\n",
    "        inputs['segs'] = ##### 코드 #####\n",
    "        inputs['clss'] = ##### 코드 #####\n",
    "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
    "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
    "\n",
    "        #Binarize label {Extracted sentence : 1, Not Extracted sentence : 0}\n",
    "        labels = labels['trg'].map(lambda  x: torch.tensor([1 if i in x else 0 for i in range(max_label_len)]))\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return [self.inputs[index][i] for i in range(5)], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea459803-8b5e-4751-852a-a9925031a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train')\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5523cfc-2e73-41cc-9c82-e6ac69eb415b",
   "metadata": {},
   "source": [
    "## 모델설계\n",
    "- `##### 코드 #####` 부분을 채워 parameter를 설정해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92a87d-f1cb-444d-b868-0561902a0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "EPOCHS = ##### 코드 #####\n",
    "LEARNING_RATE = ##### 코드 #####\n",
    "WEIGHT_DECAY = ##### 코드 #####\n",
    "NUM_WORKERS = ##### 코드 #####\n",
    "EARLY_STOPPING_PATIENCE = ##### 코드 #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576c8ee-e3a5-484c-b41a-3b4ee2d3eccf",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- 한국어 자연어 처리의 pretrained model인 KcELECTRA 깃헙 [https://github.com/Beomi/KcELECTRA] 을 참고하여 __init__ 부분을 채워보세요. \n",
    "  (괄호 안의 `##### 코드 #####` 부분)  \n",
    "- !주의! 모델이 무거우니 사용하는 파라미터 개수와 개발 환경 등을 고려하여 인코더 등을 선택하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa9332-5231-466a-af71-5d284a6e921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import transformers\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class Summarizer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(Summarizer, self).__init__()\n",
    "        self.encoder = ##### 코드 #####\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x, segs, clss, mask, mask_clss, sentence_range=None):\n",
    "        \n",
    "        top_vec = self.encoder(input_ids = x.long(), attention_mask = mask.float(),  token_type_ids = segs.long()).last_hidden_state\n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss.long()]\n",
    "        sents_vec = sents_vec * mask_clss[:, :, None].float()\n",
    "        h = self.fc(sents_vec).squeeze(-1)\n",
    "        sent_scores = self.sigmoid(h) * mask_clss.float()\n",
    "        return sent_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba85018-4434-4238-8e11-39b68c3b2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Summarizer().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd977f29-331a-4d19-8ccf-67a0778f8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hitrate(y_true, y_pred):\n",
    "    \"\"\" Metric 함수 반환하는 함수\n",
    "\n",
    "    Returns:\n",
    "        metric_fn (Callable)\n",
    "    \"\"\"\n",
    "    hitrate = np.array([len(list(set(ans).intersection(y_true[i])))/3 for i, ans in enumerate(y_pred)])\n",
    "    score = np.mean(hitrate)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177817ff-c96b-44ac-b513-809e8374676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "loss_fn = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "# Set metrics\n",
    "metric_fn = Hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e314d-2e0a-499f-84e7-37f6fc24b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int, verbose: bool, logger:logging.RootLogger=None)-> None:\n",
    "        \"\"\" 초기화\n",
    "\n",
    "        Args:\n",
    "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "            weight_path (str): weight 저장경로\n",
    "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.logger = logger\n",
    "        self.stop = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\n",
    "\n",
    "        Args:\n",
    "            loss (float):\n",
    "\n",
    "        Examples:\n",
    "            \n",
    "        Note:\n",
    "            \n",
    "        \"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopper, Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "\n",
    "            if self.verbose:\n",
    "                self.logger.info(msg) if self.logger else print(msg)\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.save_model = True\n",
    "            msg = f\"Early stopper, Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)\n",
    "\n",
    "            if self.verbose:\n",
    "                self.logger.info(msg) if self.logger else print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc4b06-532f-4a1d-9976-55906de55e44",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- Train epoch과 Validation epoch 의 loop 안의 `### 코드 ###` 부분을 채워보세요.\n",
    "- 필요한 부분을 device에 올리는 것도 잊지 마세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f258572-fe1c-409f-a0e1-fd9b993918f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" Trainer\n",
    "        epoch에 대한 학습 및 검증 절차 정의\n",
    "    \n",
    "    Attributes:\n",
    "        model (`model`)\n",
    "        device (str)\n",
    "        loss_fn (Callable)\n",
    "        metric_fn (Callable)\n",
    "        optimizer (`optimizer`)\n",
    "        scheduler (`scheduler`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, loss_fn, metric_fn, optimizer=None, scheduler=None, logger=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metric_fn = metric_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.logger = logger\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\n",
    "\n",
    "        Args:\n",
    "            dataloader (`dataloader`)\n",
    "            epoch_index (int)\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.train_total_loss = 0\n",
    "        pred_lst = []\n",
    "        target_lst = []\n",
    "        for batch_index, (data, target) in enumerate(dataloader):\n",
    "            self.optimizer.zero_grad()\n",
    "            src = data[0].to(self.device)\n",
    "            clss = ### 코드 ###\n",
    "            segs = ### 코드 ###\n",
    "            mask = ### 코드 ###\n",
    "            mask_clss = ### 코드 ###\n",
    "            target = target.float().to(self.device)\n",
    "            sent_score = ### 코드 ### \n",
    "            loss = ### 코드 ###\n",
    "            loss = (loss * mask_clss.float()).sum()\n",
    "            self.train_total_loss += loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "     \n",
    "            try:\n",
    "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
    "            except:\n",
    "                print(target)\n",
    "                sys.exit()\n",
    "                \n",
    "        self.train_mean_loss = self.train_total_loss / len(dataloader)\n",
    "        self.train_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train, loss: {self.train_mean_loss}, Score: {self.train_score}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "\n",
    "        Args:\n",
    "            dataloader (`dataloader`)\n",
    "            epoch_index (int)\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.val_total_loss = 0\n",
    "        pred_lst = []\n",
    "        target_lst = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (data, target) in enumerate(dataloader):\n",
    "\n",
    "                src = data[0].to(self.device)\n",
    "                clss = ### 코드 ###\n",
    "                segs = ### 코드 ###\n",
    "                mask = ### 코드 ###\n",
    "                mask_clss = ### 코드 ###\n",
    "                target = target.float().to(self.device)\n",
    "                sent_score = ### 코드 ###\n",
    "                loss = ### 코드 ###\n",
    "                loss = (loss * mask_clss.float()).sum()\n",
    "                self.val_total_loss += loss\n",
    "                pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
    "            self.val_mean_loss = self.val_total_loss / len(dataloader)\n",
    "            self.validation_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
    "            msg = f'Epoch {epoch_index}, Validation, loss: {self.val_mean_loss}, Score: {self.validation_score}'\n",
    "            print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a8120-3d94-4af5-b2dc-a69a6e399447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set trainer\n",
    "trainer = Trainer(model, DEVICE, loss_fn, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf8ed5-5fcf-4cda-93aa-6d7c32f84cd1",
   "metadata": {},
   "source": [
    "## 학습\n",
    "#### 코드 채워넣기\n",
    "- 위 블록에서 생성한 `train_epoch`과 `valid_epoch`을 사용해 학습을 진행하는 코드를 완성하세요. `##### 코드 #####` 부분 채우기)\n",
    "- criterion에 맞춰 모델이 자동 업데이트되고, 학습을 마치고 모델을 저장하는 부분 또한 완성하세요. (`### 코드 ###` 부분 채우기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f12453-83e0-4dd5-b329-1d148815d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "criterion = 0\n",
    "\n",
    "for epoch_index in tqdm(range(EPOCHS)):\n",
    "   \n",
    "    ##### 코드 #####\n",
    "    \n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if trainer.validation_score > criterion:\n",
    "        criterion = trainer.validation_score\n",
    "        check_point:{\n",
    "            'model' : model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        \n",
    "        ### 코드 ###\n",
    "        \n",
    "print(\"train finished, best.pt saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc3635-7e9d-4989-b279-3f6f87640e38",
   "metadata": {},
   "source": [
    "## 추론\n",
    "테스트 데이터의 타겟 변수를 `sample_submission.json` 양식에 맞춰 저장한 파일을 aiconnect 플랫폼을 통해 제출하면 추론 점수를 확인할 수 있습니다.  \n",
    "\n",
    "\"summary_index1\", \"summary_index2\", \"summary_index3\" 컬럼 값을 여러분의 모델의 추론 결과로 채워 제출 파일을 만듭니다 (현재는 모두 아래 보시는 바와 같이 동일한 값으로 채워져 있습니다). ID 값을 기준으로 채점을 진행하는 점 유의해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b2e7c-3901-4629-a5ce-5fc15cd1b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(os.path.join(DATA_DIR,'sample_submission.csv'))\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c2ed5-bad2-4da3-9cf0-02f6af7b7e7e",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- CustomDataset에서처럼 padding의 `### 코드 ###` 부분을 채워 코드를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36aa19-c02c-4701-a0d4-adef0b5847ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 클래스 정의\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\" CustomDataset과 비슷한 구조이지만 레이블이 주어지지 않음을 염두 \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "        self.inputs = self.data_loader()\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode+'_X.pt')):\n",
    "            # torch tensor 불러오기\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "        else:\n",
    "            # json 파일 불러오기\n",
    "            file_path = os.path.join(self.data_dir, self.mode + '.json')\n",
    "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
    "            inputs = pd.DataFrame(columns=['src'])\n",
    "            inputs['src'] =  df['article_original']\n",
    "      \n",
    "            # 전처리\n",
    "            inputs = self.preprocessing(inputs)\n",
    "            \n",
    "            # 다음부터는 전처리 과정을 반복하지 않기 위해 tensor 저장\n",
    "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "\n",
    "        inputs = inputs.values\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def pad(self, data, pad_id, max_len):\n",
    "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
    "        return padded_data\n",
    "\n",
    "    def preprocessing(self, inputs):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        \n",
    "        #Encoding original text\n",
    "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
    "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
    "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
    "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
    "\n",
    "        ##Padding\n",
    "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
    "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
    "        inputs['segs'] = ### 코드 ###\n",
    "        inputs['clss'] = ### 코드 ###\n",
    "        inputs['mask'] = ### 코드 ###\n",
    "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
    "     \n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return [self.inputs[index][i] for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55199f-1831-43a4-9788-48a44993a571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 로드\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, mode = 'test')\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed2152-7a7b-4477-b4c5-f07924e2f094",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- 학습된 모델을 불러와서 `### 코드 ###` 부분을 채워 추론 코드를 완성하세요\n",
    "- 필요한 부분을 device에 올리는 것을 잊지 마세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028a38d-be97-48b2-af8c-c51d6cdf374c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" 이전에 학습한 모델 weight파일을 불러 추론 \"\"\"\n",
    "MODEL_DIR = ### 모델 경로 ###\n",
    "model = Summarizer().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_DIR)['model'])\n",
    "\n",
    "# 추론\n",
    "model.eval()\n",
    "\n",
    "# 추론 결과를 pred 리스트로 저장할 예정\n",
    "pred_lst = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (data) in enumerate(test_dataloader):\n",
    "\n",
    "                clss = ### 코드 ###\n",
    "                segs = ### 코드 ###\n",
    "                mask = ### 코드 ###\n",
    "                mask_clss = ### 코드 ###\n",
    "                sent_score = ### 코드 ###\n",
    "                pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    " \n",
    "                src = data[0].to(self.device)\n",
    "\n",
    "        # 진행과정 출력\n",
    "        if batch_index % 150 == 0:\n",
    "            print(f'Prediction: {batch_index}/{len(test_dataloader)} completed')\n",
    "    print(\"Prediction all completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef207a-7717-47bf-8195-8a6ee8c1f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_lst[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936de25-6ba5-4c96-a956-c3c963d26dcd",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- sample submission 양식에 맞춰 제출할 추론 파일을 만들고 저장하세요. (`### 코드 ###` 부분 채우기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fac0c-de8f-4e63-9046-bb36243aedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 확인\n",
    "submit[['summary_index1','summary_index2','summary_index3']] = pred_lst\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49fca2c-4da2-46ca-9a28-c597f4e22a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 파일 저장\n",
    "### 코드 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e496e-53e4-4a67-bb65-07d55505db6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
